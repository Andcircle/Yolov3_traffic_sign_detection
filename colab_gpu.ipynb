{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andcircle/Yolov3_traffic_sign_detection/blob/li_traffic_sign/colab_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51bQlVgjmnWf"
      },
      "source": [
        "# YoloV3 TF2 GPU Colab Notebook\n",
        "\n",
        "##### 1.  Clone and install dependencies \n",
        "\n",
        "**IMPORTANT**: Restart following the instruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpn-5i4VHbht"
      },
      "source": [
        "!git clone https://github.com/zzh8829/yolov3-tf2\n",
        "%cd yolov3-tf2/\n",
        "!pip install -r requirements-gpu.txt dss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIUMAdGXm46J"
      },
      "source": [
        "##### 2.  Check Tensorflow2 version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyrsdB9THu-8"
      },
      "source": [
        "%cd yolov3-tf2/\n",
        "!ls\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxD-M-g4nZf_"
      },
      "source": [
        "##### 3.  Convert Pretrained Darknet Weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xymK200gmV25"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights -O data/yolov3.weights\n",
        "!python convert.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySGg4Ols02rX"
      },
      "source": [
        "##### 4. Initialize Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlgBiU4ZsZY5"
      },
      "source": [
        "import sys\n",
        "from absl import app, logging, flags\n",
        "from absl.flags import FLAGS\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (\n",
        "    YoloV3, YoloV3Tiny\n",
        ")\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "\n",
        "flags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\n",
        "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n",
        "                    'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('image', './data/girl.png', 'path to input image')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_string('output', './output.jpg', 'path to output image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "\n",
        "app._run_init(['yolov3'], app.parse_flags_with_usage)\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laxApAGV07kw"
      },
      "source": [
        "##### 4. Detect Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iKC1pvBnkDk"
      },
      "source": [
        "FLAGS.image = 'data/meme.jpg'\n",
        "\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "      \n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "logging.info('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "logging.info('classes loaded')\n",
        "\n",
        "img_raw = tf.image.decode_image(\n",
        "    open(FLAGS.image, 'rb').read(), channels=3)\n",
        "\n",
        "img = tf.expand_dims(img_raw, 0)\n",
        "img = transform_images(img, FLAGS.size)\n",
        "\n",
        "t1 = time.time()\n",
        "boxes, scores, classes, nums = yolo(img)\n",
        "t2 = time.time()\n",
        "logging.info('time: {}'.format(t2 - t1))\n",
        "\n",
        "logging.info('detections:')\n",
        "for i in range(nums[0]):\n",
        "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
        "                                        np.array(scores[0][i]),\n",
        "                                        np.array(boxes[0][i])))\n",
        "\n",
        "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
        "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up4Xcad81FSa"
      },
      "source": [
        "##### 5. Training New Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I8Ml-j4Iyuv"
      },
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar -O ./data/voc2009_raw.tar\n",
        "!mkdir -p ./data/voc2009_raw\n",
        "!tar -xf ./data/voc2009_raw.tar -C ./data/voc2009_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lvttM39I5Na"
      },
      "source": [
        "!python tools/voc2012.py \\\n",
        "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
        "  --split train \\\n",
        "  --output_file ./data/voc_train.tfrecord\n",
        "\n",
        "!python tools/voc2012.py \\\n",
        "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
        "  --split val \\\n",
        "  --output_file ./data/voc_val.tfrecord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjLHBgPKblm"
      },
      "source": [
        "!python tools/visualize_dataset.py --dataset ./data/voc_train.tfrecord --classes=./data/voc2012.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OVCJuxQKuMM"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='./output.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBhryo1I2dwG"
      },
      "source": [
        "!python train.py \\\n",
        "\t--dataset ./data/voc_train.tfrecord \\\n",
        "\t--val_dataset ./data/voc_val.tfrecord \\\n",
        "\t--classes ./data/voc2012.names \\\n",
        "\t--num_classes 20 \\\n",
        "\t--mode fit --transfer darknet \\\n",
        "\t--batch_size 16 \\\n",
        "\t--epochs 3 \\\n",
        "\t--weights ./checkpoints/yolov3.tf \\\n",
        "\t--weights_num_classes 80 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgtlCN1m1TKG"
      },
      "source": [
        "##### 6. Detect using new weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wok7x44vNYuP"
      },
      "source": [
        "FLAGS.num_classes = 20\n",
        "FLAGS.classes = 'data/voc2012.names'\n",
        "FLAGS.weights = 'checkpoints/yolov3_train_3.tf'\n",
        "FLAGS.image = 'data/meme.jpg'\n",
        "\n",
        "# Lower threshold due to insufficient training\n",
        "FLAGS.yolo_iou_threshold = 0.2\n",
        "FLAGS.yolo_score_threshold = 0.2\n",
        "\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "logging.info('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "logging.info('classes loaded')\n",
        "\n",
        "img_raw = tf.image.decode_image(\n",
        "    open(FLAGS.image, 'rb').read(), channels=3)\n",
        "\n",
        "img = tf.expand_dims(img_raw, 0)\n",
        "img = transform_images(img, FLAGS.size)\n",
        "\n",
        "t1 = time.time()\n",
        "boxes, scores, classes, nums = yolo(img)\n",
        "t2 = time.time()\n",
        "logging.info('time: {}'.format(t2 - t1))\n",
        "\n",
        "logging.info('detections:')\n",
        "for i in range(nums[0]):\n",
        "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
        "                                        np.array(scores[0][i]),\n",
        "                                        np.array(boxes[0][i])))\n",
        "\n",
        "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
        "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esTFKZzX7jYj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}